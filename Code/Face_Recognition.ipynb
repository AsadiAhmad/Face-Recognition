{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyhjLcFL/6fN+uXVLqUjPE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsadiAhmad/Face-Recognition/blob/main/Code/Face_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Import Libraries"
      ],
      "metadata": {
        "id": "8H5mblc59TEK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "U4Yf8ONb9PUp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Download Resources"
      ],
      "metadata": {
        "id": "LMvoTuAp9Wwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdown.download(id=\"1IvTKQkfYD8UOMjGPAQWY0iQK8--Qnenv\", output=\"face_detection_yunet_2023mar.onnx\", quiet=False)\n",
        "gdown.download(id=\"1Sg-y47n8Z5K099ytdgpIkVw2lOk8kD9n\", output=\"face_recognition_sface_2021dec.onnx\", quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "CFqCX7x4NCuG",
        "outputId": "b5a37eda-0d52-4561-e255-575ab890db04"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IvTKQkfYD8UOMjGPAQWY0iQK8--Qnenv\n",
            "To: /content/face_detection_yunet_2023mar.onnx\n",
            "100%|██████████| 233k/233k [00:00<00:00, 4.94MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Sg-y47n8Z5K099ytdgpIkVw2lOk8kD9n\n",
            "To: /content/face_recognition_sface_2021dec.onnx\n",
            "100%|██████████| 38.7M/38.7M [00:00<00:00, 126MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'face_recognition_sface_2021dec.onnx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/AsadiAhmad/Face-Recognition/main/Pictures/elon_musk.jpg -O elon_musk.jpg\n",
        "!wget https://raw.githubusercontent.com/AsadiAhmad/Face-Recognition/main/Videos/conference.mp4 -O conference.mp4"
      ],
      "metadata": {
        "id": "0QVHLsUw9sS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0758230f-bc8e-4d72-86ed-bf779cc64315"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-12 12:25:57--  https://raw.githubusercontent.com/AsadiAhmad/Face-Recognition/main/Pictures/elon_musk.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31340 (31K) [image/jpeg]\n",
            "Saving to: ‘elon_musk.jpg’\n",
            "\n",
            "\relon_musk.jpg         0%[                    ]       0  --.-KB/s               \relon_musk.jpg       100%[===================>]  30.61K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-05-12 12:25:57 (1.94 MB/s) - ‘elon_musk.jpg’ saved [31340/31340]\n",
            "\n",
            "--2025-05-12 12:25:57--  https://raw.githubusercontent.com/AsadiAhmad/Face-Recognition/main/Videos/conference.mp4\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3373800 (3.2M) [application/octet-stream]\n",
            "Saving to: ‘conference.mp4’\n",
            "\n",
            "conference.mp4      100%[===================>]   3.22M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-05-12 12:25:57 (28.1 MB/s) - ‘conference.mp4’ saved [3373800/3373800]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Load Images and Videos"
      ],
      "metadata": {
        "id": "euHtDKK09slQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv.imread('elon_musk.jpg')\n",
        "cap = cv.VideoCapture('conference.mp4')\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open video.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "CRm0ap_g9uem"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Define Detector Model"
      ],
      "metadata": {
        "id": "5zwNHs31FEEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detector = cv.FaceDetectorYN.create(\n",
        "    \"face_detection_yunet_2023mar.onnx\",\n",
        "    \"\",\n",
        "    (320, 320),\n",
        "    0.8,\n",
        "    0.3,\n",
        "    5000\n",
        ")"
      ],
      "metadata": {
        "id": "tnRqpHP6FF8m"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Define Recognizer Model"
      ],
      "metadata": {
        "id": "yO3DjXa3N1Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recognizer = cv.FaceRecognizerSF.create(\"face_recognition_sface_2021dec.onnx\",\"\")"
      ],
      "metadata": {
        "id": "aqAzmYWUN59n"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Extracting feature for the selected photo"
      ],
      "metadata": {
        "id": "q9ivEAHnO7LC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "height, width, _ = image.shape\n",
        "detector.setInputSize((width, height))\n",
        "main_faces = detector.detect(image)\n",
        "main_face_align = recognizer.alignCrop(image, main_faces[1][0])\n",
        "main_face_feature = recognizer.feature(main_face_align)"
      ],
      "metadata": {
        "id": "uN2rME0ePNJU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Set Parameters"
      ],
      "metadata": {
        "id": "k1_JQNj4GV7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fps = int(cap.get(cv.CAP_PROP_FPS))\n",
        "width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "output_path = 'face_detected.mp4'\n",
        "fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "detector.setInputSize((width, height))"
      ],
      "metadata": {
        "id": "90Xh715XIH10"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Process Video Frame by Frame"
      ],
      "metadata": {
        "id": "BvpLu1IKtLlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rectangle_faces(input, faces, index, color=(0, 0, 255), thickness=2):\n",
        "    if faces[1] is not None:\n",
        "        for idx, face in enumerate(faces[1]):\n",
        "            coords = face[:-1].astype(np.int32)\n",
        "            if idx == index:\n",
        "                cv.rectangle(input, (coords[0], coords[1]), (coords[0]+coords[2], coords[1]+coords[3]), (0, 255, 0), thickness)\n",
        "            else:\n",
        "                cv.rectangle(input, (coords[0], coords[1]), (coords[0]+coords[2], coords[1]+coords[3]), color, thickness)"
      ],
      "metadata": {
        "id": "21AtDavEIe-Z"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def match_faces(face_feature1, face_feature2):\n",
        "    cosine_similarity_threshold = 0.363\n",
        "    cosine_score = recognizer.match(face_feature1, face_feature2, cv.FaceRecognizerSF_FR_COSINE)\n",
        "\n",
        "    if cosine_score >= cosine_similarity_threshold:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "metadata": {
        "id": "3WHnsywYSlyn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        print(\"Reached end of video.\")\n",
        "        break\n",
        "\n",
        "    detected_face_index = -1\n",
        "    faces = detector.detect(frame)\n",
        "\n",
        "    if faces[1] is not None:\n",
        "        for index, face in enumerate(faces[1]):\n",
        "            face_align = recognizer.alignCrop(frame, face)\n",
        "            face_feature = recognizer.feature(face_align)\n",
        "\n",
        "            if match_faces(face_feature, main_face_feature) and detected_face_index == -1:\n",
        "                detected_face_index = index\n",
        "\n",
        "        rectangle_faces(frame, faces, detected_face_index)\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh_LKcUxEfWU",
        "outputId": "6ca52125-7841-4977-d0bd-3f5fcaba5a45"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reached end of video.\n"
          ]
        }
      ]
    }
  ]
}